{
 "metadata": {
  "name": "",
  "signature": "sha256:1dcd12776db7ff84bf3a88c7bee02d59e8968ad517718154d09fc137644d2969"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This post describes a simple yet flexible implementation on how to deploy an [IPython.parallel](http://ipython.org/ipython-doc/dev/parallel/) cluster in multiple EC2 instances using [salt](http://www.saltstack.com/) and a little bit of [Vagrant](http://vagrantup.com/). The final output will be one instance running the IPython notebook, `ipcontroller` and acting as the salt-master, also 6 instances each one running `ipengine` and being salt-minions, see the [IPython.parallel docs](http://ipython.org/ipython-doc/dev/parallel/) for information on those commands.\n",
      "\n",
      "In a previous post I created a [one-liner for deploying an ipython notebook](http://danielfrg.com/blog/2013/11/27/ipython-notebook-aws-salt/) to the cloud, after that I have been refactoring and advancing the concept and it became my own [datasciencebox](https://github.com/danielfrg/datasciencebox), it was natural to include the code for creating the ipcluster code in the same project."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Why\n",
      "\n",
      "Let me begin saying that I know about [starcluster](http://star.mit.edu/cluster/) I have used it (for this same task) and I believe is the best way to create cluster for doing parallel computing but it lacks of a few features:\n",
      "\n",
      "1. Only EC2 support: I use EC2 and a couple of AWS services everyday but what if I want to move to rackspace or any other cloud? So instead of relying on boto I use [salt-cloud](http://docs.saltstack.com/en/latest/topics/cloud/) that relies on [apache libcloud](https://libcloud.apache.org/)\n",
      "2. Dependency of installing the scientific libraries from pypi: I use anaconda on my mac and I wanted to use the same versions on the cloud, using the [salt state I wrote previously](http://danielfrg.com/blog/2013/11/27/ipython-notebook-aws-salt/) this was an easy task. With this having the latest version is as simple as changing the `requirements.txt`\n",
      "3. Plugins are python classes (see the [starcluster ipython plugin for example](https://github.com/jtriley/StarCluster/blob/develop/starcluster/plugins/ipcluster.py)): While this is completely fine once you learn configuration management you don't want to come back, a salt state is much more easier to create and mantain\n",
      "\n",
      "**Why not hadoop?** Again, I use hadoop every week, but for me it seams more natural to do the analysis on your tool of choice (python or R) and then scale it using the same (or similar) tool, it doesn't make a lot of sense to do the analysis on a tool just becuase it scales if it lacks the capabilities you need, for example the excelente interactivity of IPython."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How\n",
      "\n",
      "###Requirements\n",
      "\n",
      "1. [Vagrant](http://www.vagrantup.com/) (+[aws-plugin](https://github.com/mitchellh/vagrant-aws)) to create the an EC2 instance that runs the ipython notebook. Note you could on run this on Rackspace by using [vagrant-rackspace](https://github.com/mitchellh/vagrant-rackspace)\n",
      "2. `git clone` the [datasciencebox](https://github.com/danielfrg/datasciencebox) repo\n",
      "3. AWS account credentials\n",
      "4. Copy your EC2 keypair in the root of the repo of step 2 and name it `ipcluster.pem`, this is so Vagrant can copy the keypair to the cloud\n",
      "\n",
      "###Let's get started\n",
      "\n",
      "1. `cd` to that directory open the `Vagrantfile` and fill the values inside `config.vm.provider`, mainly the AWS credentials.\n",
      "2. `vagrant up --provider=aws`\n",
      "\n",
      "Now you have an IPython notebook running in the new instance on port 8888"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###ipcluster\n",
      "\n",
      "First, `shh` into the instance by running `vagrant ssh`.\n",
      "\n",
      "You need to know the private address of the instance. Use this one-liner to get it: `python -c 'import socket; print socket.gethostbyname(socket.gethostname())'` it should print something like: `10.2.182.86`\n",
      "\n",
      "Start the `ipcontroller` by running the `ipcluster` salt state, you need to add a couple of values, mainly the aws and ec2 instances settings:\n",
      "\n",
      "```\n",
      "sudo salt-call state.sls ipcluster pillar='{ipcluster: {master: {MASTER_ADDRESS}, keyname: {AWS_KEYPAIR_NAME}, securitygroup: {EC2_SECURITY_GROUP_NAME}}, aws: {access_key: {AWS_ACCESS_KEY}, secret_key: {AWS_SECRET_KEY}}}'\n",
      "```\n",
      "\n",
      "The previous command will install the dependencies of `salt-cloud` and start the `ipcontroller` process.\n",
      "\n",
      "Now you need to create the instances that are going to run the `ipengine`: `sudo salt-cloud -p base_ec2 ipython-minion-X` where `X` can be a number or string, i ran it with 1 and 2 for this example. This command will create the new instances, install the `salt-minion` and connect it to the `salt-master`.\n",
      "\n",
      "To test that the minions are running run:\n",
      "\n",
      "```\n",
      "\u21aa sudo salt '*' test.ping\n",
      "ipython-minion-1:\n",
      "    True\n",
      "ipython-minion-2:\n",
      "    True\n",
      "```\n",
      "\n",
      "Now start the `ipengine` on each minion by running the `ipcluster-minion` salt state, this will also provision the same python environment using anaconda. Run `sudo salt '*' saltutil.sync_all` and after `sudo salt '*' state.sls ipcluster-minion`\n",
      "\n",
      "Everything should be in place now, go to the notebook and connect to the clients:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "client = Client()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(client)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that there are four clients since by default it will be 2 `ipengine`s per instance. We can check the address and pid of each engine:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def where_am_i():\n",
      "    import os\n",
      "    import socket\n",
      "    \n",
      "    return \"In process with pid {0} on host: '{1}'\".format(os.getpid(), socket.gethostname())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "where_am_i()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "\"In process with pid 15314 on host: 'ip-10-151-123-100'\""
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "direct_view = client.direct_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "where_am_i_direct_results = direct_view.apply(where_am_i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "where_am_i_direct_results.get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[\"In process with pid 14018 on host: 'domU-12-31-39-16-52-7E'\",\n",
        " \"In process with pid 14019 on host: 'domU-12-31-39-16-52-7E'\",\n",
        " \"In process with pid 13956 on host: 'ip-10-110-86-251'\",\n",
        " \"In process with pid 13955 on host: 'ip-10-110-86-251'\"]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that there are two process on each instance.\n",
      "\n",
      "Now lets add one more machine by running:\n",
      "\n",
      "1. `sudo salt-cloud -p base_ec2 ipython-minion-3`\n",
      "2. `sudo salt '*' saltutil.sync_all`\n",
      "3. `sudo salt '*' state.sls ipcluster-minion`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(client)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "6"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "where_am_i_direct_results = direct_view.apply(where_am_i)\n",
      "where_am_i_direct_results.get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[\"In process with pid 14617 on host: 'domU-12-31-39-16-52-7E'\",\n",
        " \"In process with pid 14618 on host: 'domU-12-31-39-16-52-7E'\",\n",
        " \"In process with pid 14554 on host: 'ip-10-110-86-251'\",\n",
        " \"In process with pid 14553 on host: 'ip-10-110-86-251'\",\n",
        " \"In process with pid 14006 on host: 'ip-10-191-45-204'\",\n",
        " \"In process with pid 14007 on host: 'ip-10-191-45-204'\"]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There was no need to restart the notebook or anything, IPython.parallel took care of everything.\n",
      "\n",
      "Since we bootstrapped the same python environment using anaconda we can use the scientific libraries, for example numpy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "A = np.random.random((2,2))\n",
      "ev = numpy.linalg.eigvals(A)\n",
      "ev.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[4:3]: \u001b[0m1.0222318748650969"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[5:3]: \u001b[0m1.138421700991769"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[6:3]: \u001b[0m1.0188265649715529"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[7:3]: \u001b[0m0.74439354047097206"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[8:3]: \u001b[0m1.468974252745251"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "\u001b[0;31mOut[9:3]: \u001b[0m0.92031189875595965"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Conclusions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It was relatively simple to get 6 workers running on the cloud and while it is not as simple as creating a config file and run one command as startcluster most of the stuff can be easily wrapped in a command line utility.\n",
      "\n",
      "It was also simple to write this code since it was no code just salt states, I also learned about salt-cloud and like salt even more now.\n",
      "\n",
      "Finally is worth saying that there are dozens of examples of what you can do with IPython.parallel on the web, one of my favorites is by Olivier Grisel where he does [machine learning with sklearn](http://nbviewer.ipython.org/gist/anonymous/5115540/Model%20Selection%20for%20the%20Nystroem%20Method.ipynb)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
